{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_sparse\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, input_channels, out_channels):\n",
    "        super(Conv, self).__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_channels, out_channels))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        out = torch_sparse.matmul(adj, x) + self.bias\n",
    "        return out\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_channels, out_channels, hidden_channels, num_layers, p):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(Conv(input_channels, hidden_channels))\n",
    "        \n",
    "        self.bns = nn.ModuleList()\n",
    "        self.bns.append(nn.BatchNorm1d(hidden_channels))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(Conv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(nn.BatchNorm1d(hidden_channels))\n",
    "            \n",
    "        self.convs.append(Conv(hidden_channels, out_channels))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, adj)\n",
    "            x = self.bns[i](x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        out = self.convs[-1](x, adj)\n",
    "        return out\n",
    "\n",
    "def train(model, data, train_idx, optimizer, criterion):\n",
    "    model.train()\n",
    "    \n",
    "    model.zero_grad()\n",
    "    outputs = model(data.x, data.adj_t)[train_idx]\n",
    "    loss = criterion(outputs, data.y.squeeze(1)[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    model.eval()\n",
    "    \n",
    "    outputs = model(data.x, data.adj_t)\n",
    "    y_pred = outputs.argmax(dim=1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "hidden_channels = 256\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "epochs = 500\n",
    "log_steps = 1\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='../dataset', transform=T.ToSparseTensor())\n",
    "\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(data.num_features, dataset.num_classes, hidden_channels, num_layers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name='ogbn-arxiv')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 01, Loss: 3.9477, Train: 26.65%, Valid: 29.29% Test: 26.34%\n",
      "Run: 01, Epoch: 02, Loss: 2.3603, Train: 29.00%, Valid: 30.13% Test: 35.09%\n",
      "Run: 01, Epoch: 03, Loss: 1.9769, Train: 29.28%, Valid: 29.36% Test: 32.77%\n",
      "Run: 01, Epoch: 04, Loss: 1.7967, Train: 28.94%, Valid: 24.46% Test: 23.08%\n",
      "Run: 01, Epoch: 05, Loss: 1.6758, Train: 34.74%, Valid: 29.80% Test: 29.49%\n",
      "Run: 01, Epoch: 06, Loss: 1.5711, Train: 41.19%, Valid: 37.40% Test: 41.55%\n",
      "Run: 01, Epoch: 07, Loss: 1.4975, Train: 41.76%, Valid: 38.06% Test: 42.68%\n",
      "Run: 01, Epoch: 08, Loss: 1.4542, Train: 43.07%, Valid: 37.61% Test: 41.57%\n",
      "Run: 01, Epoch: 09, Loss: 1.4036, Train: 44.34%, Valid: 34.39% Test: 36.70%\n",
      "Run: 01, Epoch: 10, Loss: 1.3596, Train: 45.19%, Valid: 32.98% Test: 34.49%\n",
      "Run: 01, Epoch: 11, Loss: 1.3296, Train: 46.05%, Valid: 34.82% Test: 37.33%\n",
      "Run: 01, Epoch: 12, Loss: 1.3057, Train: 46.39%, Valid: 37.94% Test: 41.49%\n",
      "Run: 01, Epoch: 13, Loss: 1.2796, Train: 47.41%, Valid: 43.46% Test: 47.23%\n",
      "Run: 01, Epoch: 14, Loss: 1.2588, Train: 49.65%, Valid: 48.93% Test: 51.88%\n",
      "Run: 01, Epoch: 15, Loss: 1.2439, Train: 51.84%, Valid: 52.96% Test: 55.85%\n",
      "Run: 01, Epoch: 16, Loss: 1.2235, Train: 53.42%, Valid: 55.49% Test: 58.28%\n",
      "Run: 01, Epoch: 17, Loss: 1.2078, Train: 54.64%, Valid: 57.23% Test: 59.55%\n",
      "Run: 01, Epoch: 18, Loss: 1.2053, Train: 55.54%, Valid: 58.33% Test: 60.19%\n",
      "Run: 01, Epoch: 19, Loss: 1.1913, Train: 56.59%, Valid: 59.25% Test: 60.41%\n",
      "Run: 01, Epoch: 20, Loss: 1.1794, Train: 57.76%, Valid: 59.97% Test: 60.56%\n",
      "Run: 01, Epoch: 21, Loss: 1.1678, Train: 59.21%, Valid: 60.75% Test: 61.01%\n",
      "Run: 01, Epoch: 22, Loss: 1.1621, Train: 60.31%, Valid: 61.50% Test: 62.10%\n",
      "Run: 01, Epoch: 23, Loss: 1.1527, Train: 61.31%, Valid: 62.05% Test: 63.13%\n",
      "Run: 01, Epoch: 24, Loss: 1.1388, Train: 62.05%, Valid: 62.36% Test: 63.69%\n",
      "Run: 01, Epoch: 25, Loss: 1.1299, Train: 63.15%, Valid: 63.16% Test: 64.26%\n",
      "Run: 01, Epoch: 26, Loss: 1.1199, Train: 64.39%, Valid: 64.36% Test: 64.55%\n",
      "Run: 01, Epoch: 27, Loss: 1.1112, Train: 65.37%, Valid: 65.07% Test: 64.76%\n",
      "Run: 01, Epoch: 28, Loss: 1.1122, Train: 65.94%, Valid: 65.65% Test: 65.34%\n",
      "Run: 01, Epoch: 29, Loss: 1.0995, Train: 66.15%, Valid: 66.11% Test: 66.07%\n",
      "Run: 01, Epoch: 30, Loss: 1.0971, Train: 65.78%, Valid: 65.39% Test: 66.15%\n",
      "Run: 01, Epoch: 31, Loss: 1.0893, Train: 65.61%, Valid: 65.01% Test: 66.01%\n",
      "Run: 01, Epoch: 32, Loss: 1.0880, Train: 66.54%, Valid: 66.11% Test: 66.86%\n",
      "Run: 01, Epoch: 33, Loss: 1.0781, Train: 67.60%, Valid: 67.35% Test: 67.66%\n",
      "Run: 01, Epoch: 34, Loss: 1.0719, Train: 68.32%, Valid: 68.00% Test: 67.94%\n",
      "Run: 01, Epoch: 35, Loss: 1.0664, Train: 68.60%, Valid: 68.29% Test: 68.05%\n",
      "Run: 01, Epoch: 36, Loss: 1.0637, Train: 68.77%, Valid: 68.25% Test: 68.12%\n",
      "Run: 01, Epoch: 37, Loss: 1.0543, Train: 68.80%, Valid: 67.98% Test: 67.86%\n",
      "Run: 01, Epoch: 38, Loss: 1.0525, Train: 68.76%, Valid: 67.87% Test: 67.74%\n",
      "Run: 01, Epoch: 39, Loss: 1.0478, Train: 68.91%, Valid: 68.22% Test: 67.97%\n",
      "Run: 01, Epoch: 40, Loss: 1.0466, Train: 69.25%, Valid: 68.51% Test: 68.35%\n",
      "Run: 01, Epoch: 41, Loss: 1.0406, Train: 69.68%, Valid: 68.93% Test: 68.93%\n",
      "Run: 01, Epoch: 42, Loss: 1.0373, Train: 69.93%, Valid: 69.31% Test: 69.17%\n",
      "Run: 01, Epoch: 43, Loss: 1.0352, Train: 70.09%, Valid: 69.41% Test: 69.30%\n",
      "Run: 01, Epoch: 44, Loss: 1.0311, Train: 70.29%, Valid: 69.60% Test: 69.48%\n",
      "Run: 01, Epoch: 45, Loss: 1.0271, Train: 70.40%, Valid: 69.71% Test: 69.63%\n",
      "Run: 01, Epoch: 46, Loss: 1.0226, Train: 70.52%, Valid: 69.91% Test: 69.67%\n",
      "Run: 01, Epoch: 47, Loss: 1.0188, Train: 70.76%, Valid: 70.19% Test: 69.52%\n",
      "Run: 01, Epoch: 48, Loss: 1.0168, Train: 70.91%, Valid: 70.09% Test: 69.22%\n",
      "Run: 01, Epoch: 49, Loss: 1.0131, Train: 71.04%, Valid: 70.07% Test: 69.19%\n",
      "Run: 01, Epoch: 50, Loss: 1.0102, Train: 71.20%, Valid: 70.18% Test: 69.30%\n",
      "Run: 01, Epoch: 51, Loss: 1.0080, Train: 71.32%, Valid: 70.21% Test: 69.10%\n",
      "Run: 01, Epoch: 52, Loss: 1.0075, Train: 71.47%, Valid: 70.16% Test: 68.79%\n",
      "Run: 01, Epoch: 53, Loss: 1.0002, Train: 71.56%, Valid: 70.27% Test: 68.89%\n",
      "Run: 01, Epoch: 54, Loss: 1.0010, Train: 71.57%, Valid: 70.67% Test: 69.79%\n",
      "Run: 01, Epoch: 55, Loss: 0.9950, Train: 71.57%, Valid: 70.78% Test: 70.20%\n",
      "Run: 01, Epoch: 56, Loss: 0.9938, Train: 71.73%, Valid: 70.83% Test: 70.08%\n",
      "Run: 01, Epoch: 57, Loss: 0.9920, Train: 71.81%, Valid: 70.56% Test: 69.30%\n",
      "Run: 01, Epoch: 58, Loss: 0.9881, Train: 71.67%, Valid: 70.31% Test: 68.64%\n",
      "Run: 01, Epoch: 59, Loss: 0.9854, Train: 71.73%, Valid: 70.50% Test: 69.84%\n",
      "Run: 01, Epoch: 60, Loss: 0.9873, Train: 71.76%, Valid: 70.72% Test: 70.28%\n",
      "Run: 01, Epoch: 61, Loss: 0.9797, Train: 71.83%, Valid: 70.72% Test: 70.27%\n",
      "Run: 01, Epoch: 62, Loss: 0.9824, Train: 71.94%, Valid: 70.84% Test: 70.05%\n",
      "Run: 01, Epoch: 63, Loss: 0.9757, Train: 72.15%, Valid: 70.65% Test: 69.39%\n",
      "Run: 01, Epoch: 64, Loss: 0.9763, Train: 72.20%, Valid: 70.51% Test: 69.11%\n",
      "Run: 01, Epoch: 65, Loss: 0.9712, Train: 72.21%, Valid: 70.84% Test: 69.86%\n",
      "Run: 01, Epoch: 66, Loss: 0.9709, Train: 72.18%, Valid: 71.21% Test: 70.40%\n",
      "Run: 01, Epoch: 67, Loss: 0.9672, Train: 72.30%, Valid: 71.20% Test: 70.36%\n",
      "Run: 01, Epoch: 68, Loss: 0.9647, Train: 72.38%, Valid: 71.42% Test: 70.45%\n",
      "Run: 01, Epoch: 69, Loss: 0.9641, Train: 72.40%, Valid: 71.42% Test: 70.89%\n",
      "Run: 01, Epoch: 70, Loss: 0.9625, Train: 72.44%, Valid: 71.35% Test: 70.95%\n",
      "Run: 01, Epoch: 71, Loss: 0.9615, Train: 72.72%, Valid: 71.33% Test: 70.49%\n",
      "Run: 01, Epoch: 72, Loss: 0.9565, Train: 72.71%, Valid: 70.89% Test: 69.46%\n",
      "Run: 01, Epoch: 73, Loss: 0.9561, Train: 72.73%, Valid: 70.82% Test: 69.39%\n",
      "Run: 01, Epoch: 74, Loss: 0.9542, Train: 72.67%, Valid: 71.06% Test: 69.87%\n",
      "Run: 01, Epoch: 75, Loss: 0.9539, Train: 72.69%, Valid: 71.15% Test: 70.19%\n",
      "Run: 01, Epoch: 76, Loss: 0.9513, Train: 72.72%, Valid: 71.12% Test: 69.79%\n",
      "Run: 01, Epoch: 77, Loss: 0.9492, Train: 72.66%, Valid: 71.02% Test: 69.92%\n",
      "Run: 01, Epoch: 78, Loss: 0.9441, Train: 72.77%, Valid: 71.28% Test: 70.21%\n",
      "Run: 01, Epoch: 79, Loss: 0.9439, Train: 72.85%, Valid: 71.37% Test: 70.50%\n",
      "Run: 01, Epoch: 80, Loss: 0.9449, Train: 72.91%, Valid: 71.29% Test: 70.10%\n",
      "Run: 01, Epoch: 81, Loss: 0.9453, Train: 72.97%, Valid: 71.25% Test: 70.06%\n",
      "Run: 01, Epoch: 82, Loss: 0.9402, Train: 72.98%, Valid: 71.19% Test: 70.28%\n",
      "Run: 01, Epoch: 83, Loss: 0.9384, Train: 73.08%, Valid: 71.42% Test: 70.42%\n",
      "Run: 01, Epoch: 84, Loss: 0.9374, Train: 73.20%, Valid: 71.49% Test: 70.41%\n",
      "Run: 01, Epoch: 85, Loss: 0.9383, Train: 73.24%, Valid: 71.53% Test: 70.40%\n",
      "Run: 01, Epoch: 86, Loss: 0.9342, Train: 73.29%, Valid: 71.49% Test: 70.32%\n",
      "Run: 01, Epoch: 87, Loss: 0.9352, Train: 73.30%, Valid: 71.19% Test: 69.63%\n",
      "Run: 01, Epoch: 88, Loss: 0.9292, Train: 73.32%, Valid: 70.91% Test: 68.91%\n",
      "Run: 01, Epoch: 89, Loss: 0.9330, Train: 73.41%, Valid: 71.30% Test: 69.97%\n",
      "Run: 01, Epoch: 90, Loss: 0.9258, Train: 73.37%, Valid: 71.54% Test: 70.64%\n",
      "Run: 01, Epoch: 91, Loss: 0.9262, Train: 73.43%, Valid: 71.37% Test: 70.01%\n",
      "Run: 01, Epoch: 92, Loss: 0.9242, Train: 73.59%, Valid: 71.22% Test: 69.70%\n",
      "Run: 01, Epoch: 93, Loss: 0.9254, Train: 73.73%, Valid: 71.76% Test: 70.72%\n",
      "Run: 01, Epoch: 94, Loss: 0.9205, Train: 73.76%, Valid: 71.71% Test: 70.56%\n",
      "Run: 01, Epoch: 95, Loss: 0.9226, Train: 73.61%, Valid: 71.47% Test: 69.89%\n",
      "Run: 01, Epoch: 96, Loss: 0.9207, Train: 73.61%, Valid: 71.36% Test: 69.67%\n",
      "Run: 01, Epoch: 97, Loss: 0.9170, Train: 73.70%, Valid: 71.68% Test: 70.66%\n",
      "Run: 01, Epoch: 98, Loss: 0.9163, Train: 73.79%, Valid: 71.80% Test: 70.72%\n",
      "Run: 01, Epoch: 99, Loss: 0.9131, Train: 73.61%, Valid: 70.90% Test: 69.11%\n",
      "Run: 01, Epoch: 100, Loss: 0.9122, Train: 73.61%, Valid: 70.58% Test: 68.45%\n",
      "Run: 01, Epoch: 101, Loss: 0.9114, Train: 73.93%, Valid: 71.75% Test: 70.62%\n",
      "Run: 01, Epoch: 102, Loss: 0.9081, Train: 73.99%, Valid: 71.87% Test: 70.90%\n",
      "Run: 01, Epoch: 103, Loss: 0.9082, Train: 74.09%, Valid: 71.98% Test: 70.92%\n",
      "Run: 01, Epoch: 104, Loss: 0.9056, Train: 74.06%, Valid: 71.94% Test: 71.31%\n",
      "Run: 01, Epoch: 105, Loss: 0.9064, Train: 74.00%, Valid: 71.85% Test: 71.23%\n",
      "Run: 01, Epoch: 106, Loss: 0.9016, Train: 74.09%, Valid: 71.84% Test: 70.72%\n",
      "Run: 01, Epoch: 107, Loss: 0.9056, Train: 73.97%, Valid: 71.55% Test: 70.40%\n",
      "Run: 01, Epoch: 108, Loss: 0.9011, Train: 73.77%, Valid: 71.38% Test: 70.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 109, Loss: 0.9026, Train: 73.91%, Valid: 71.48% Test: 70.08%\n",
      "Run: 01, Epoch: 110, Loss: 0.8995, Train: 74.06%, Valid: 71.95% Test: 71.09%\n",
      "Run: 01, Epoch: 111, Loss: 0.8998, Train: 74.11%, Valid: 71.94% Test: 71.19%\n",
      "Run: 01, Epoch: 112, Loss: 0.8965, Train: 74.21%, Valid: 71.74% Test: 70.52%\n",
      "Run: 01, Epoch: 113, Loss: 0.8942, Train: 74.18%, Valid: 71.87% Test: 70.98%\n",
      "Run: 01, Epoch: 114, Loss: 0.8948, Train: 73.91%, Valid: 71.38% Test: 70.68%\n",
      "Run: 01, Epoch: 115, Loss: 0.8939, Train: 74.13%, Valid: 71.16% Test: 69.91%\n",
      "Run: 01, Epoch: 116, Loss: 0.8898, Train: 74.12%, Valid: 70.90% Test: 69.21%\n",
      "Run: 01, Epoch: 117, Loss: 0.8901, Train: 74.19%, Valid: 72.00% Test: 71.30%\n",
      "Run: 01, Epoch: 118, Loss: 0.8904, Train: 74.26%, Valid: 72.12% Test: 71.43%\n",
      "Run: 01, Epoch: 119, Loss: 0.8885, Train: 74.46%, Valid: 71.69% Test: 70.52%\n",
      "Run: 01, Epoch: 120, Loss: 0.8889, Train: 74.54%, Valid: 71.67% Test: 70.43%\n",
      "Run: 01, Epoch: 121, Loss: 0.8888, Train: 74.51%, Valid: 71.82% Test: 71.36%\n",
      "Run: 01, Epoch: 122, Loss: 0.8823, Train: 74.44%, Valid: 72.00% Test: 71.50%\n",
      "Run: 01, Epoch: 123, Loss: 0.8854, Train: 74.35%, Valid: 71.52% Test: 70.29%\n",
      "Run: 01, Epoch: 124, Loss: 0.8823, Train: 74.51%, Valid: 71.88% Test: 71.06%\n",
      "Run: 01, Epoch: 125, Loss: 0.8787, Train: 74.55%, Valid: 71.64% Test: 70.54%\n",
      "Run: 01, Epoch: 126, Loss: 0.8794, Train: 74.65%, Valid: 71.35% Test: 69.92%\n",
      "Run: 01, Epoch: 127, Loss: 0.8808, Train: 74.55%, Valid: 71.45% Test: 70.22%\n",
      "Run: 01, Epoch: 128, Loss: 0.8790, Train: 74.38%, Valid: 71.55% Test: 70.47%\n",
      "Run: 01, Epoch: 129, Loss: 0.8773, Train: 74.63%, Valid: 71.57% Test: 70.23%\n",
      "Run: 01, Epoch: 130, Loss: 0.8761, Train: 74.63%, Valid: 71.97% Test: 71.39%\n",
      "Run: 01, Epoch: 131, Loss: 0.8738, Train: 74.48%, Valid: 71.94% Test: 71.49%\n",
      "Run: 01, Epoch: 132, Loss: 0.8734, Train: 74.82%, Valid: 72.17% Test: 70.90%\n",
      "Run: 01, Epoch: 133, Loss: 0.8729, Train: 74.84%, Valid: 71.93% Test: 70.56%\n",
      "Run: 01, Epoch: 134, Loss: 0.8729, Train: 74.76%, Valid: 72.14% Test: 71.60%\n",
      "Run: 01, Epoch: 135, Loss: 0.8711, Train: 74.86%, Valid: 71.88% Test: 70.51%\n",
      "Run: 01, Epoch: 136, Loss: 0.8702, Train: 74.82%, Valid: 71.75% Test: 70.32%\n",
      "Run: 01, Epoch: 137, Loss: 0.8673, Train: 74.65%, Valid: 71.58% Test: 70.61%\n",
      "Run: 01, Epoch: 138, Loss: 0.8663, Train: 74.76%, Valid: 71.02% Test: 69.32%\n",
      "Run: 01, Epoch: 139, Loss: 0.8667, Train: 75.05%, Valid: 71.63% Test: 70.05%\n",
      "Run: 01, Epoch: 140, Loss: 0.8649, Train: 75.07%, Valid: 72.36% Test: 71.81%\n",
      "Run: 01, Epoch: 141, Loss: 0.8626, Train: 75.23%, Valid: 72.34% Test: 71.59%\n",
      "Run: 01, Epoch: 142, Loss: 0.8653, Train: 75.13%, Valid: 71.81% Test: 70.22%\n",
      "Run: 01, Epoch: 143, Loss: 0.8625, Train: 75.21%, Valid: 72.09% Test: 71.24%\n",
      "Run: 01, Epoch: 144, Loss: 0.8601, Train: 75.32%, Valid: 72.40% Test: 71.70%\n",
      "Run: 01, Epoch: 145, Loss: 0.8616, Train: 75.31%, Valid: 72.03% Test: 70.87%\n",
      "Run: 01, Epoch: 146, Loss: 0.8569, Train: 75.24%, Valid: 72.06% Test: 71.26%\n",
      "Run: 01, Epoch: 147, Loss: 0.8596, Train: 75.30%, Valid: 71.80% Test: 70.38%\n",
      "Run: 01, Epoch: 148, Loss: 0.8569, Train: 75.36%, Valid: 72.11% Test: 71.05%\n",
      "Run: 01, Epoch: 149, Loss: 0.8546, Train: 75.35%, Valid: 72.21% Test: 71.29%\n",
      "Run: 01, Epoch: 150, Loss: 0.8552, Train: 75.63%, Valid: 71.84% Test: 70.62%\n",
      "Run: 01, Epoch: 151, Loss: 0.8509, Train: 75.17%, Valid: 71.40% Test: 70.66%\n",
      "Run: 01, Epoch: 152, Loss: 0.8531, Train: 75.09%, Valid: 71.19% Test: 70.25%\n",
      "Run: 01, Epoch: 153, Loss: 0.8521, Train: 75.46%, Valid: 71.81% Test: 70.48%\n",
      "Run: 01, Epoch: 154, Loss: 0.8500, Train: 75.49%, Valid: 72.30% Test: 71.30%\n",
      "Run: 01, Epoch: 155, Loss: 0.8517, Train: 75.64%, Valid: 72.55% Test: 71.83%\n",
      "Run: 01, Epoch: 156, Loss: 0.8490, Train: 75.57%, Valid: 72.27% Test: 71.41%\n",
      "Run: 01, Epoch: 157, Loss: 0.8485, Train: 75.38%, Valid: 72.10% Test: 71.10%\n",
      "Run: 01, Epoch: 158, Loss: 0.8491, Train: 75.26%, Valid: 72.33% Test: 71.65%\n",
      "Run: 01, Epoch: 159, Loss: 0.8446, Train: 75.42%, Valid: 72.52% Test: 71.79%\n",
      "Run: 01, Epoch: 160, Loss: 0.8454, Train: 75.37%, Valid: 72.08% Test: 71.33%\n",
      "Run: 01, Epoch: 161, Loss: 0.8439, Train: 75.33%, Valid: 71.19% Test: 69.54%\n",
      "Run: 01, Epoch: 162, Loss: 0.8443, Train: 75.24%, Valid: 70.75% Test: 68.53%\n",
      "Run: 01, Epoch: 163, Loss: 0.8436, Train: 75.54%, Valid: 72.30% Test: 71.21%\n",
      "Run: 01, Epoch: 164, Loss: 0.8443, Train: 75.17%, Valid: 72.27% Test: 72.17%\n",
      "Run: 01, Epoch: 165, Loss: 0.8422, Train: 75.69%, Valid: 72.41% Test: 72.03%\n",
      "Run: 01, Epoch: 166, Loss: 0.8412, Train: 75.10%, Valid: 70.54% Test: 68.30%\n",
      "Run: 01, Epoch: 167, Loss: 0.8373, Train: 75.45%, Valid: 71.35% Test: 69.79%\n",
      "Run: 01, Epoch: 168, Loss: 0.8390, Train: 75.64%, Valid: 72.00% Test: 71.26%\n",
      "Run: 01, Epoch: 169, Loss: 0.8383, Train: 75.51%, Valid: 71.33% Test: 69.63%\n",
      "Run: 01, Epoch: 170, Loss: 0.8367, Train: 75.69%, Valid: 72.21% Test: 71.43%\n",
      "Run: 01, Epoch: 171, Loss: 0.8337, Train: 75.76%, Valid: 72.39% Test: 71.66%\n",
      "Run: 01, Epoch: 172, Loss: 0.8352, Train: 75.75%, Valid: 71.94% Test: 70.56%\n",
      "Run: 01, Epoch: 173, Loss: 0.8355, Train: 75.97%, Valid: 72.33% Test: 71.01%\n",
      "Run: 01, Epoch: 174, Loss: 0.8321, Train: 76.03%, Valid: 72.33% Test: 70.88%\n",
      "Run: 01, Epoch: 175, Loss: 0.8327, Train: 75.90%, Valid: 72.41% Test: 71.60%\n",
      "Run: 01, Epoch: 176, Loss: 0.8314, Train: 75.88%, Valid: 72.43% Test: 72.09%\n",
      "Run: 01, Epoch: 177, Loss: 0.8301, Train: 75.99%, Valid: 71.78% Test: 70.49%\n",
      "Run: 01, Epoch: 178, Loss: 0.8279, Train: 75.69%, Valid: 71.26% Test: 69.65%\n",
      "Run: 01, Epoch: 179, Loss: 0.8289, Train: 76.08%, Valid: 72.59% Test: 71.96%\n",
      "Run: 01, Epoch: 180, Loss: 0.8299, Train: 75.70%, Valid: 71.81% Test: 71.01%\n",
      "Run: 01, Epoch: 181, Loss: 0.8284, Train: 76.08%, Valid: 71.71% Test: 70.16%\n",
      "Run: 01, Epoch: 182, Loss: 0.8294, Train: 75.85%, Valid: 71.55% Test: 69.96%\n",
      "Run: 01, Epoch: 183, Loss: 0.8281, Train: 75.90%, Valid: 71.67% Test: 70.43%\n",
      "Run: 01, Epoch: 184, Loss: 0.8239, Train: 76.06%, Valid: 72.53% Test: 72.04%\n",
      "Run: 01, Epoch: 185, Loss: 0.8225, Train: 75.80%, Valid: 72.47% Test: 71.95%\n",
      "Run: 01, Epoch: 186, Loss: 0.8247, Train: 76.13%, Valid: 72.56% Test: 71.37%\n",
      "Run: 01, Epoch: 187, Loss: 0.8220, Train: 76.19%, Valid: 72.26% Test: 70.88%\n",
      "Run: 01, Epoch: 188, Loss: 0.8209, Train: 76.11%, Valid: 72.28% Test: 71.53%\n",
      "Run: 01, Epoch: 189, Loss: 0.8220, Train: 75.99%, Valid: 70.86% Test: 68.90%\n",
      "Run: 01, Epoch: 190, Loss: 0.8268, Train: 75.87%, Valid: 71.84% Test: 70.97%\n",
      "Run: 01, Epoch: 191, Loss: 0.8180, Train: 75.67%, Valid: 70.78% Test: 68.76%\n",
      "Run: 01, Epoch: 192, Loss: 0.8197, Train: 76.02%, Valid: 71.19% Test: 69.24%\n",
      "Run: 01, Epoch: 193, Loss: 0.8196, Train: 76.31%, Valid: 72.48% Test: 71.98%\n",
      "Run: 01, Epoch: 194, Loss: 0.8191, Train: 76.03%, Valid: 72.61% Test: 71.90%\n",
      "Run: 01, Epoch: 195, Loss: 0.8179, Train: 75.97%, Valid: 72.58% Test: 72.14%\n",
      "Run: 01, Epoch: 196, Loss: 0.8153, Train: 76.32%, Valid: 72.57% Test: 71.93%\n",
      "Run: 01, Epoch: 197, Loss: 0.8132, Train: 76.25%, Valid: 71.54% Test: 69.67%\n",
      "Run: 01, Epoch: 198, Loss: 0.8133, Train: 76.68%, Valid: 72.48% Test: 71.56%\n",
      "Run: 01, Epoch: 199, Loss: 0.8151, Train: 76.61%, Valid: 72.66% Test: 72.04%\n",
      "Run: 01, Epoch: 200, Loss: 0.8133, Train: 76.29%, Valid: 72.37% Test: 71.71%\n",
      "Run: 01, Epoch: 201, Loss: 0.8141, Train: 76.11%, Valid: 72.35% Test: 71.73%\n",
      "Run: 01, Epoch: 202, Loss: 0.8127, Train: 76.25%, Valid: 72.14% Test: 70.45%\n",
      "Run: 01, Epoch: 203, Loss: 0.8126, Train: 76.19%, Valid: 71.84% Test: 70.25%\n",
      "Run: 01, Epoch: 204, Loss: 0.8083, Train: 76.57%, Valid: 71.97% Test: 70.57%\n",
      "Run: 01, Epoch: 205, Loss: 0.8112, Train: 76.69%, Valid: 72.35% Test: 70.90%\n",
      "Run: 01, Epoch: 206, Loss: 0.8124, Train: 76.56%, Valid: 72.42% Test: 72.01%\n",
      "Run: 01, Epoch: 207, Loss: 0.8093, Train: 76.72%, Valid: 72.56% Test: 71.54%\n",
      "Run: 01, Epoch: 208, Loss: 0.8070, Train: 76.85%, Valid: 72.44% Test: 71.19%\n",
      "Run: 01, Epoch: 209, Loss: 0.8066, Train: 76.54%, Valid: 71.22% Test: 69.01%\n",
      "Run: 01, Epoch: 210, Loss: 0.8056, Train: 76.52%, Valid: 71.88% Test: 70.17%\n",
      "Run: 01, Epoch: 211, Loss: 0.8067, Train: 76.52%, Valid: 72.79% Test: 71.98%\n",
      "Run: 01, Epoch: 212, Loss: 0.8052, Train: 76.52%, Valid: 72.42% Test: 71.38%\n",
      "Run: 01, Epoch: 213, Loss: 0.8074, Train: 76.53%, Valid: 72.12% Test: 71.04%\n",
      "Run: 01, Epoch: 214, Loss: 0.8013, Train: 76.63%, Valid: 72.55% Test: 71.57%\n",
      "Run: 01, Epoch: 215, Loss: 0.8032, Train: 76.63%, Valid: 72.46% Test: 71.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 216, Loss: 0.8026, Train: 76.85%, Valid: 72.93% Test: 72.12%\n",
      "Run: 01, Epoch: 217, Loss: 0.8000, Train: 76.88%, Valid: 72.63% Test: 71.68%\n",
      "Run: 01, Epoch: 218, Loss: 0.8024, Train: 76.41%, Valid: 70.76% Test: 68.21%\n",
      "Run: 01, Epoch: 219, Loss: 0.8025, Train: 75.85%, Valid: 71.64% Test: 71.58%\n",
      "Run: 01, Epoch: 220, Loss: 0.8013, Train: 76.90%, Valid: 72.38% Test: 71.25%\n",
      "Run: 01, Epoch: 221, Loss: 0.8014, Train: 76.57%, Valid: 72.26% Test: 71.37%\n",
      "Run: 01, Epoch: 222, Loss: 0.8009, Train: 76.58%, Valid: 72.18% Test: 70.91%\n",
      "Run: 01, Epoch: 223, Loss: 0.8000, Train: 76.91%, Valid: 72.31% Test: 71.29%\n",
      "Run: 01, Epoch: 224, Loss: 0.8010, Train: 76.94%, Valid: 72.46% Test: 71.62%\n",
      "Run: 01, Epoch: 225, Loss: 0.7958, Train: 76.66%, Valid: 72.54% Test: 72.09%\n",
      "Run: 01, Epoch: 226, Loss: 0.7962, Train: 77.03%, Valid: 71.94% Test: 69.87%\n",
      "Run: 01, Epoch: 227, Loss: 0.7950, Train: 76.98%, Valid: 72.24% Test: 70.64%\n",
      "Run: 01, Epoch: 228, Loss: 0.7960, Train: 76.81%, Valid: 71.36% Test: 69.30%\n",
      "Run: 01, Epoch: 229, Loss: 0.7973, Train: 76.43%, Valid: 71.71% Test: 70.32%\n",
      "Run: 01, Epoch: 230, Loss: 0.7950, Train: 76.77%, Valid: 72.44% Test: 71.73%\n",
      "Run: 01, Epoch: 231, Loss: 0.7922, Train: 76.82%, Valid: 72.47% Test: 72.24%\n",
      "Run: 01, Epoch: 232, Loss: 0.7892, Train: 77.22%, Valid: 72.37% Test: 71.38%\n",
      "Run: 01, Epoch: 233, Loss: 0.7922, Train: 77.17%, Valid: 72.48% Test: 71.39%\n",
      "Run: 01, Epoch: 234, Loss: 0.7901, Train: 77.22%, Valid: 72.20% Test: 70.83%\n",
      "Run: 01, Epoch: 235, Loss: 0.7891, Train: 77.12%, Valid: 72.50% Test: 71.08%\n",
      "Run: 01, Epoch: 236, Loss: 0.7880, Train: 76.77%, Valid: 70.88% Test: 68.35%\n",
      "Run: 01, Epoch: 237, Loss: 0.7913, Train: 76.61%, Valid: 71.87% Test: 70.92%\n",
      "Run: 01, Epoch: 238, Loss: 0.7893, Train: 76.74%, Valid: 72.47% Test: 71.70%\n",
      "Run: 01, Epoch: 239, Loss: 0.7932, Train: 77.02%, Valid: 72.33% Test: 70.69%\n",
      "Run: 01, Epoch: 240, Loss: 0.7867, Train: 76.82%, Valid: 72.58% Test: 71.91%\n",
      "Run: 01, Epoch: 241, Loss: 0.7884, Train: 77.11%, Valid: 72.82% Test: 72.27%\n",
      "Run: 01, Epoch: 242, Loss: 0.7875, Train: 76.57%, Valid: 71.85% Test: 71.71%\n",
      "Run: 01, Epoch: 243, Loss: 0.7879, Train: 77.04%, Valid: 71.57% Test: 69.91%\n",
      "Run: 01, Epoch: 244, Loss: 0.7872, Train: 77.17%, Valid: 72.07% Test: 70.90%\n",
      "Run: 01, Epoch: 245, Loss: 0.7825, Train: 77.16%, Valid: 72.54% Test: 71.34%\n",
      "Run: 01, Epoch: 246, Loss: 0.7863, Train: 77.05%, Valid: 71.52% Test: 69.60%\n",
      "Run: 01, Epoch: 247, Loss: 0.7859, Train: 77.07%, Valid: 72.68% Test: 71.64%\n",
      "Run: 01, Epoch: 248, Loss: 0.7807, Train: 76.93%, Valid: 72.88% Test: 72.22%\n",
      "Run: 01, Epoch: 249, Loss: 0.7839, Train: 76.81%, Valid: 71.48% Test: 69.43%\n",
      "Run: 01, Epoch: 250, Loss: 0.7840, Train: 77.14%, Valid: 72.79% Test: 72.17%\n",
      "Run: 01, Epoch: 251, Loss: 0.7798, Train: 76.62%, Valid: 72.00% Test: 71.54%\n",
      "Run: 01, Epoch: 252, Loss: 0.7855, Train: 77.13%, Valid: 71.40% Test: 69.70%\n",
      "Run: 01, Epoch: 253, Loss: 0.7871, Train: 76.99%, Valid: 72.24% Test: 71.35%\n",
      "Run: 01, Epoch: 254, Loss: 0.7801, Train: 77.27%, Valid: 72.49% Test: 71.92%\n",
      "Run: 01, Epoch: 255, Loss: 0.7816, Train: 76.53%, Valid: 69.96% Test: 67.55%\n",
      "Run: 01, Epoch: 256, Loss: 0.7846, Train: 77.10%, Valid: 71.77% Test: 70.21%\n",
      "Run: 01, Epoch: 257, Loss: 0.7797, Train: 77.18%, Valid: 72.85% Test: 72.08%\n",
      "Run: 01, Epoch: 258, Loss: 0.7818, Train: 77.21%, Valid: 72.61% Test: 71.41%\n",
      "Run: 01, Epoch: 259, Loss: 0.7770, Train: 77.16%, Valid: 72.74% Test: 71.26%\n",
      "Run: 01, Epoch: 260, Loss: 0.7783, Train: 77.27%, Valid: 72.69% Test: 71.57%\n",
      "Run: 01, Epoch: 261, Loss: 0.7762, Train: 77.27%, Valid: 71.77% Test: 69.85%\n",
      "Run: 01, Epoch: 262, Loss: 0.7776, Train: 77.15%, Valid: 71.69% Test: 69.84%\n",
      "Run: 01, Epoch: 263, Loss: 0.7773, Train: 77.48%, Valid: 72.41% Test: 71.13%\n",
      "Run: 01, Epoch: 264, Loss: 0.7750, Train: 77.34%, Valid: 72.73% Test: 72.35%\n",
      "Run: 01, Epoch: 265, Loss: 0.7727, Train: 77.15%, Valid: 72.28% Test: 71.77%\n",
      "Run: 01, Epoch: 266, Loss: 0.7734, Train: 77.42%, Valid: 72.58% Test: 71.89%\n",
      "Run: 01, Epoch: 267, Loss: 0.7727, Train: 77.61%, Valid: 72.71% Test: 71.75%\n",
      "Run: 01, Epoch: 268, Loss: 0.7756, Train: 77.46%, Valid: 71.98% Test: 70.34%\n",
      "Run: 01, Epoch: 269, Loss: 0.7743, Train: 77.55%, Valid: 72.60% Test: 71.78%\n",
      "Run: 01, Epoch: 270, Loss: 0.7717, Train: 77.37%, Valid: 72.76% Test: 71.97%\n",
      "Run: 01, Epoch: 271, Loss: 0.7721, Train: 76.97%, Valid: 72.16% Test: 71.67%\n",
      "Run: 01, Epoch: 272, Loss: 0.7697, Train: 77.22%, Valid: 72.21% Test: 70.66%\n",
      "Run: 01, Epoch: 273, Loss: 0.7691, Train: 77.21%, Valid: 71.99% Test: 70.13%\n",
      "Run: 01, Epoch: 274, Loss: 0.7691, Train: 77.10%, Valid: 71.06% Test: 68.74%\n",
      "Run: 01, Epoch: 275, Loss: 0.7717, Train: 77.38%, Valid: 72.41% Test: 71.24%\n",
      "Run: 01, Epoch: 276, Loss: 0.7689, Train: 77.67%, Valid: 72.27% Test: 70.94%\n",
      "Run: 01, Epoch: 277, Loss: 0.7697, Train: 77.58%, Valid: 72.25% Test: 71.34%\n",
      "Run: 01, Epoch: 278, Loss: 0.7676, Train: 77.96%, Valid: 72.11% Test: 70.47%\n",
      "Run: 01, Epoch: 279, Loss: 0.7678, Train: 77.71%, Valid: 71.67% Test: 69.27%\n",
      "Run: 01, Epoch: 280, Loss: 0.7669, Train: 77.75%, Valid: 72.67% Test: 71.48%\n",
      "Run: 01, Epoch: 281, Loss: 0.7656, Train: 77.60%, Valid: 72.82% Test: 72.39%\n",
      "Run: 01, Epoch: 282, Loss: 0.7696, Train: 77.05%, Valid: 72.51% Test: 72.35%\n",
      "Run: 01, Epoch: 283, Loss: 0.7650, Train: 77.56%, Valid: 72.64% Test: 71.55%\n",
      "Run: 01, Epoch: 284, Loss: 0.7661, Train: 77.88%, Valid: 72.46% Test: 71.19%\n",
      "Run: 01, Epoch: 285, Loss: 0.7663, Train: 77.83%, Valid: 72.41% Test: 71.42%\n",
      "Run: 01, Epoch: 286, Loss: 0.7618, Train: 77.46%, Valid: 71.96% Test: 70.78%\n",
      "Run: 01, Epoch: 287, Loss: 0.7624, Train: 77.36%, Valid: 71.85% Test: 70.83%\n",
      "Run: 01, Epoch: 288, Loss: 0.7647, Train: 77.89%, Valid: 72.05% Test: 70.61%\n",
      "Run: 01, Epoch: 289, Loss: 0.7577, Train: 77.52%, Valid: 72.26% Test: 70.86%\n",
      "Run: 01, Epoch: 290, Loss: 0.7621, Train: 77.73%, Valid: 72.56% Test: 71.49%\n",
      "Run: 01, Epoch: 291, Loss: 0.7636, Train: 77.88%, Valid: 72.36% Test: 71.08%\n",
      "Run: 01, Epoch: 292, Loss: 0.7624, Train: 77.51%, Valid: 72.36% Test: 71.55%\n",
      "Run: 01, Epoch: 293, Loss: 0.7640, Train: 77.65%, Valid: 72.26% Test: 70.73%\n",
      "Run: 01, Epoch: 294, Loss: 0.7597, Train: 77.50%, Valid: 71.05% Test: 68.23%\n",
      "Run: 01, Epoch: 295, Loss: 0.7608, Train: 77.83%, Valid: 71.93% Test: 70.10%\n",
      "Run: 01, Epoch: 296, Loss: 0.7589, Train: 77.95%, Valid: 72.31% Test: 70.83%\n",
      "Run: 01, Epoch: 297, Loss: 0.7606, Train: 77.70%, Valid: 71.66% Test: 69.55%\n",
      "Run: 01, Epoch: 298, Loss: 0.7618, Train: 77.77%, Valid: 72.79% Test: 71.75%\n",
      "Run: 01, Epoch: 299, Loss: 0.7588, Train: 77.43%, Valid: 71.57% Test: 69.67%\n",
      "Run: 01, Epoch: 300, Loss: 0.7600, Train: 77.47%, Valid: 72.29% Test: 71.27%\n",
      "Run: 01, Epoch: 301, Loss: 0.7584, Train: 77.58%, Valid: 72.49% Test: 71.21%\n",
      "Run: 01, Epoch: 302, Loss: 0.7564, Train: 77.69%, Valid: 72.27% Test: 70.91%\n",
      "Run: 01, Epoch: 303, Loss: 0.7616, Train: 76.90%, Valid: 71.39% Test: 70.76%\n",
      "Run: 01, Epoch: 304, Loss: 0.7579, Train: 77.64%, Valid: 71.61% Test: 69.67%\n",
      "Run: 01, Epoch: 305, Loss: 0.7578, Train: 77.84%, Valid: 70.88% Test: 68.49%\n",
      "Run: 01, Epoch: 306, Loss: 0.7550, Train: 78.17%, Valid: 71.81% Test: 69.72%\n",
      "Run: 01, Epoch: 307, Loss: 0.7533, Train: 77.67%, Valid: 71.24% Test: 68.96%\n",
      "Run: 01, Epoch: 308, Loss: 0.7511, Train: 77.94%, Valid: 72.52% Test: 71.20%\n",
      "Run: 01, Epoch: 309, Loss: 0.7539, Train: 78.08%, Valid: 72.24% Test: 71.01%\n",
      "Run: 01, Epoch: 310, Loss: 0.7557, Train: 78.08%, Valid: 72.10% Test: 70.48%\n",
      "Run: 01, Epoch: 311, Loss: 0.7494, Train: 77.86%, Valid: 71.48% Test: 70.26%\n",
      "Run: 01, Epoch: 312, Loss: 0.7517, Train: 78.14%, Valid: 72.20% Test: 70.84%\n",
      "Run: 01, Epoch: 313, Loss: 0.7566, Train: 78.26%, Valid: 73.07% Test: 72.40%\n",
      "Run: 01, Epoch: 314, Loss: 0.7495, Train: 78.33%, Valid: 72.42% Test: 70.34%\n",
      "Run: 01, Epoch: 315, Loss: 0.7537, Train: 78.19%, Valid: 72.30% Test: 70.50%\n",
      "Run: 01, Epoch: 316, Loss: 0.7495, Train: 78.12%, Valid: 72.70% Test: 71.60%\n",
      "Run: 01, Epoch: 317, Loss: 0.7528, Train: 78.14%, Valid: 71.98% Test: 70.44%\n",
      "Run: 01, Epoch: 318, Loss: 0.7511, Train: 77.96%, Valid: 72.25% Test: 71.52%\n",
      "Run: 01, Epoch: 319, Loss: 0.7512, Train: 78.17%, Valid: 72.22% Test: 71.63%\n",
      "Run: 01, Epoch: 320, Loss: 0.7475, Train: 77.78%, Valid: 70.98% Test: 68.68%\n",
      "Run: 01, Epoch: 321, Loss: 0.7522, Train: 78.06%, Valid: 72.57% Test: 71.35%\n",
      "Run: 01, Epoch: 322, Loss: 0.7512, Train: 78.20%, Valid: 72.24% Test: 70.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 323, Loss: 0.7507, Train: 78.36%, Valid: 71.80% Test: 69.63%\n",
      "Run: 01, Epoch: 324, Loss: 0.7505, Train: 78.00%, Valid: 72.15% Test: 71.24%\n",
      "Run: 01, Epoch: 325, Loss: 0.7484, Train: 78.20%, Valid: 72.24% Test: 70.74%\n",
      "Run: 01, Epoch: 326, Loss: 0.7463, Train: 78.29%, Valid: 72.17% Test: 70.96%\n",
      "Run: 01, Epoch: 327, Loss: 0.7480, Train: 78.20%, Valid: 72.47% Test: 71.48%\n",
      "Run: 01, Epoch: 328, Loss: 0.7477, Train: 78.15%, Valid: 72.70% Test: 72.11%\n",
      "Run: 01, Epoch: 329, Loss: 0.7465, Train: 77.88%, Valid: 72.36% Test: 71.59%\n",
      "Run: 01, Epoch: 330, Loss: 0.7446, Train: 77.70%, Valid: 71.98% Test: 70.47%\n",
      "Run: 01, Epoch: 331, Loss: 0.7439, Train: 77.83%, Valid: 70.89% Test: 68.66%\n",
      "Run: 01, Epoch: 332, Loss: 0.7442, Train: 78.01%, Valid: 71.77% Test: 70.33%\n",
      "Run: 01, Epoch: 333, Loss: 0.7514, Train: 78.26%, Valid: 71.52% Test: 69.54%\n",
      "Run: 01, Epoch: 334, Loss: 0.7455, Train: 78.28%, Valid: 72.05% Test: 70.65%\n",
      "Run: 01, Epoch: 335, Loss: 0.7450, Train: 77.07%, Valid: 72.00% Test: 72.02%\n",
      "Run: 01, Epoch: 336, Loss: 0.7456, Train: 78.09%, Valid: 72.48% Test: 71.58%\n",
      "Run: 01, Epoch: 337, Loss: 0.7414, Train: 78.06%, Valid: 71.29% Test: 69.06%\n",
      "Run: 01, Epoch: 338, Loss: 0.7469, Train: 78.28%, Valid: 72.46% Test: 71.00%\n",
      "Run: 01, Epoch: 339, Loss: 0.7488, Train: 78.15%, Valid: 72.03% Test: 70.43%\n",
      "Run: 01, Epoch: 340, Loss: 0.7446, Train: 77.95%, Valid: 71.69% Test: 70.16%\n",
      "Run: 01, Epoch: 341, Loss: 0.7442, Train: 78.41%, Valid: 72.82% Test: 72.06%\n",
      "Run: 01, Epoch: 342, Loss: 0.7424, Train: 78.17%, Valid: 72.48% Test: 71.30%\n",
      "Run: 01, Epoch: 343, Loss: 0.7411, Train: 78.24%, Valid: 72.23% Test: 70.57%\n",
      "Run: 01, Epoch: 344, Loss: 0.7415, Train: 78.24%, Valid: 72.24% Test: 70.98%\n",
      "Run: 01, Epoch: 345, Loss: 0.7416, Train: 78.37%, Valid: 72.38% Test: 70.81%\n",
      "Run: 01, Epoch: 346, Loss: 0.7441, Train: 78.29%, Valid: 72.53% Test: 71.49%\n",
      "Run: 01, Epoch: 347, Loss: 0.7414, Train: 78.38%, Valid: 71.33% Test: 69.08%\n",
      "Run: 01, Epoch: 348, Loss: 0.7403, Train: 78.40%, Valid: 72.40% Test: 71.41%\n",
      "Run: 01, Epoch: 349, Loss: 0.7419, Train: 78.42%, Valid: 71.93% Test: 70.35%\n",
      "Run: 01, Epoch: 350, Loss: 0.7444, Train: 77.96%, Valid: 71.84% Test: 70.44%\n",
      "Run: 01, Epoch: 351, Loss: 0.7430, Train: 78.20%, Valid: 72.15% Test: 70.74%\n",
      "Run: 01, Epoch: 352, Loss: 0.7433, Train: 78.27%, Valid: 72.70% Test: 71.87%\n",
      "Run: 01, Epoch: 353, Loss: 0.7382, Train: 78.24%, Valid: 72.64% Test: 71.63%\n",
      "Run: 01, Epoch: 354, Loss: 0.7445, Train: 77.75%, Valid: 72.35% Test: 70.49%\n",
      "Run: 01, Epoch: 355, Loss: 0.7413, Train: 77.73%, Valid: 72.12% Test: 70.96%\n",
      "Run: 01, Epoch: 356, Loss: 0.7405, Train: 77.56%, Valid: 70.94% Test: 69.05%\n",
      "Run: 01, Epoch: 357, Loss: 0.7425, Train: 78.06%, Valid: 72.21% Test: 71.56%\n",
      "Run: 01, Epoch: 358, Loss: 0.7382, Train: 78.41%, Valid: 72.38% Test: 71.68%\n",
      "Run: 01, Epoch: 359, Loss: 0.7379, Train: 78.11%, Valid: 71.77% Test: 70.49%\n",
      "Run: 01, Epoch: 360, Loss: 0.7384, Train: 78.18%, Valid: 71.84% Test: 70.56%\n",
      "Run: 01, Epoch: 361, Loss: 0.7374, Train: 78.34%, Valid: 72.53% Test: 71.65%\n",
      "Run: 01, Epoch: 362, Loss: 0.7381, Train: 78.25%, Valid: 72.40% Test: 71.09%\n",
      "Run: 01, Epoch: 363, Loss: 0.7339, Train: 78.23%, Valid: 72.23% Test: 70.87%\n",
      "Run: 01, Epoch: 364, Loss: 0.7325, Train: 78.41%, Valid: 71.74% Test: 70.01%\n",
      "Run: 01, Epoch: 365, Loss: 0.7346, Train: 78.67%, Valid: 72.40% Test: 70.85%\n",
      "Run: 01, Epoch: 366, Loss: 0.7358, Train: 78.70%, Valid: 72.34% Test: 70.68%\n",
      "Run: 01, Epoch: 367, Loss: 0.7351, Train: 78.59%, Valid: 72.74% Test: 71.41%\n",
      "Run: 01, Epoch: 368, Loss: 0.7308, Train: 77.69%, Valid: 71.62% Test: 71.30%\n",
      "Run: 01, Epoch: 369, Loss: 0.7350, Train: 77.92%, Valid: 71.94% Test: 71.76%\n",
      "Run: 01, Epoch: 370, Loss: 0.7299, Train: 78.72%, Valid: 72.62% Test: 71.76%\n",
      "Run: 01, Epoch: 371, Loss: 0.7303, Train: 79.04%, Valid: 72.23% Test: 70.32%\n",
      "Run: 01, Epoch: 372, Loss: 0.7287, Train: 79.05%, Valid: 72.20% Test: 70.33%\n",
      "Run: 01, Epoch: 373, Loss: 0.7311, Train: 78.77%, Valid: 71.54% Test: 69.00%\n",
      "Run: 01, Epoch: 374, Loss: 0.7296, Train: 78.82%, Valid: 71.99% Test: 69.90%\n",
      "Run: 01, Epoch: 375, Loss: 0.7293, Train: 78.74%, Valid: 72.63% Test: 70.93%\n",
      "Run: 01, Epoch: 376, Loss: 0.7273, Train: 78.94%, Valid: 73.01% Test: 71.65%\n",
      "Run: 01, Epoch: 377, Loss: 0.7271, Train: 78.99%, Valid: 72.40% Test: 70.48%\n",
      "Run: 01, Epoch: 378, Loss: 0.7269, Train: 79.02%, Valid: 72.60% Test: 71.17%\n",
      "Run: 01, Epoch: 379, Loss: 0.7286, Train: 79.05%, Valid: 72.38% Test: 70.44%\n",
      "Run: 01, Epoch: 380, Loss: 0.7267, Train: 78.85%, Valid: 72.35% Test: 71.05%\n",
      "Run: 01, Epoch: 381, Loss: 0.7292, Train: 78.48%, Valid: 71.71% Test: 70.39%\n",
      "Run: 01, Epoch: 382, Loss: 0.7284, Train: 78.96%, Valid: 72.02% Test: 70.11%\n",
      "Run: 01, Epoch: 383, Loss: 0.7279, Train: 78.79%, Valid: 72.95% Test: 72.47%\n",
      "Run: 01, Epoch: 384, Loss: 0.7252, Train: 78.49%, Valid: 71.78% Test: 69.33%\n",
      "Run: 01, Epoch: 385, Loss: 0.7305, Train: 78.57%, Valid: 72.17% Test: 70.29%\n",
      "Run: 01, Epoch: 386, Loss: 0.7283, Train: 78.89%, Valid: 72.44% Test: 70.80%\n",
      "Run: 01, Epoch: 387, Loss: 0.7276, Train: 78.93%, Valid: 71.72% Test: 69.71%\n",
      "Run: 01, Epoch: 388, Loss: 0.7261, Train: 78.40%, Valid: 71.92% Test: 71.08%\n",
      "Run: 01, Epoch: 389, Loss: 0.7289, Train: 78.66%, Valid: 72.40% Test: 71.39%\n",
      "Run: 01, Epoch: 390, Loss: 0.7274, Train: 78.93%, Valid: 72.29% Test: 70.94%\n",
      "Run: 01, Epoch: 391, Loss: 0.7263, Train: 78.63%, Valid: 71.98% Test: 69.95%\n",
      "Run: 01, Epoch: 392, Loss: 0.7274, Train: 78.19%, Valid: 71.15% Test: 68.46%\n",
      "Run: 01, Epoch: 393, Loss: 0.7292, Train: 78.42%, Valid: 72.36% Test: 71.25%\n",
      "Run: 01, Epoch: 394, Loss: 0.7251, Train: 78.66%, Valid: 71.73% Test: 70.66%\n",
      "Run: 01, Epoch: 395, Loss: 0.7241, Train: 78.58%, Valid: 71.65% Test: 70.28%\n",
      "Run: 01, Epoch: 396, Loss: 0.7303, Train: 78.90%, Valid: 72.84% Test: 72.35%\n",
      "Run: 01, Epoch: 397, Loss: 0.7267, Train: 78.62%, Valid: 72.11% Test: 70.13%\n",
      "Run: 01, Epoch: 398, Loss: 0.7253, Train: 78.61%, Valid: 72.38% Test: 70.34%\n",
      "Run: 01, Epoch: 399, Loss: 0.7271, Train: 78.61%, Valid: 71.42% Test: 69.31%\n",
      "Run: 01, Epoch: 400, Loss: 0.7224, Train: 78.96%, Valid: 71.15% Test: 68.53%\n",
      "Run: 01, Epoch: 401, Loss: 0.7237, Train: 78.43%, Valid: 71.88% Test: 70.95%\n",
      "Run: 01, Epoch: 402, Loss: 0.7230, Train: 78.65%, Valid: 72.07% Test: 71.22%\n",
      "Run: 01, Epoch: 403, Loss: 0.7215, Train: 78.87%, Valid: 72.47% Test: 71.27%\n",
      "Run: 01, Epoch: 404, Loss: 0.7242, Train: 78.76%, Valid: 72.84% Test: 72.10%\n",
      "Run: 01, Epoch: 405, Loss: 0.7225, Train: 78.84%, Valid: 72.04% Test: 70.35%\n",
      "Run: 01, Epoch: 406, Loss: 0.7224, Train: 79.27%, Valid: 72.80% Test: 71.11%\n",
      "Run: 01, Epoch: 407, Loss: 0.7204, Train: 78.79%, Valid: 71.99% Test: 69.80%\n",
      "Run: 01, Epoch: 408, Loss: 0.7220, Train: 78.56%, Valid: 71.88% Test: 70.13%\n",
      "Run: 01, Epoch: 409, Loss: 0.7177, Train: 79.13%, Valid: 72.37% Test: 70.35%\n",
      "Run: 01, Epoch: 410, Loss: 0.7169, Train: 79.15%, Valid: 71.85% Test: 69.79%\n",
      "Run: 01, Epoch: 411, Loss: 0.7187, Train: 79.03%, Valid: 72.03% Test: 70.21%\n",
      "Run: 01, Epoch: 412, Loss: 0.7203, Train: 79.06%, Valid: 72.60% Test: 71.45%\n",
      "Run: 01, Epoch: 413, Loss: 0.7175, Train: 79.16%, Valid: 72.82% Test: 71.92%\n",
      "Run: 01, Epoch: 414, Loss: 0.7173, Train: 79.08%, Valid: 72.52% Test: 71.42%\n",
      "Run: 01, Epoch: 415, Loss: 0.7199, Train: 79.18%, Valid: 72.33% Test: 70.50%\n",
      "Run: 01, Epoch: 416, Loss: 0.7180, Train: 79.01%, Valid: 72.57% Test: 71.19%\n",
      "Run: 01, Epoch: 417, Loss: 0.7179, Train: 79.07%, Valid: 72.69% Test: 70.91%\n",
      "Run: 01, Epoch: 418, Loss: 0.7192, Train: 78.77%, Valid: 72.01% Test: 70.20%\n",
      "Run: 01, Epoch: 419, Loss: 0.7191, Train: 78.80%, Valid: 70.96% Test: 68.28%\n",
      "Run: 01, Epoch: 420, Loss: 0.7214, Train: 78.83%, Valid: 72.53% Test: 72.19%\n",
      "Run: 01, Epoch: 421, Loss: 0.7228, Train: 79.05%, Valid: 72.23% Test: 70.58%\n",
      "Run: 01, Epoch: 422, Loss: 0.7211, Train: 78.42%, Valid: 71.76% Test: 70.89%\n",
      "Run: 01, Epoch: 423, Loss: 0.7220, Train: 79.27%, Valid: 72.29% Test: 71.59%\n",
      "Run: 01, Epoch: 424, Loss: 0.7165, Train: 79.13%, Valid: 72.72% Test: 71.90%\n",
      "Run: 01, Epoch: 425, Loss: 0.7175, Train: 78.56%, Valid: 72.46% Test: 71.57%\n",
      "Run: 01, Epoch: 426, Loss: 0.7196, Train: 78.92%, Valid: 71.07% Test: 68.08%\n",
      "Run: 01, Epoch: 427, Loss: 0.7175, Train: 78.81%, Valid: 70.84% Test: 68.07%\n",
      "Run: 01, Epoch: 428, Loss: 0.7160, Train: 78.65%, Valid: 71.84% Test: 70.22%\n",
      "Run: 01, Epoch: 429, Loss: 0.7175, Train: 78.37%, Valid: 70.78% Test: 68.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 430, Loss: 0.7172, Train: 78.96%, Valid: 72.09% Test: 71.06%\n",
      "Run: 01, Epoch: 431, Loss: 0.7181, Train: 78.55%, Valid: 72.45% Test: 72.02%\n",
      "Run: 01, Epoch: 432, Loss: 0.7189, Train: 78.95%, Valid: 72.18% Test: 70.52%\n",
      "Run: 01, Epoch: 433, Loss: 0.7142, Train: 79.27%, Valid: 72.55% Test: 70.43%\n",
      "Run: 01, Epoch: 434, Loss: 0.7167, Train: 79.36%, Valid: 72.38% Test: 70.58%\n",
      "Run: 01, Epoch: 435, Loss: 0.7167, Train: 79.31%, Valid: 71.97% Test: 70.00%\n",
      "Run: 01, Epoch: 436, Loss: 0.7135, Train: 79.24%, Valid: 71.51% Test: 69.44%\n",
      "Run: 01, Epoch: 437, Loss: 0.7140, Train: 79.17%, Valid: 72.57% Test: 71.48%\n",
      "Run: 01, Epoch: 438, Loss: 0.7153, Train: 79.25%, Valid: 72.91% Test: 71.79%\n",
      "Run: 01, Epoch: 439, Loss: 0.7138, Train: 79.08%, Valid: 72.10% Test: 69.73%\n",
      "Run: 01, Epoch: 440, Loss: 0.7133, Train: 79.39%, Valid: 72.31% Test: 70.10%\n",
      "Run: 01, Epoch: 441, Loss: 0.7120, Train: 79.30%, Valid: 72.23% Test: 70.37%\n",
      "Run: 01, Epoch: 442, Loss: 0.7105, Train: 78.90%, Valid: 71.89% Test: 69.89%\n",
      "Run: 01, Epoch: 443, Loss: 0.7109, Train: 78.97%, Valid: 72.04% Test: 70.00%\n",
      "Run: 01, Epoch: 444, Loss: 0.7136, Train: 79.47%, Valid: 72.77% Test: 71.23%\n",
      "Run: 01, Epoch: 445, Loss: 0.7081, Train: 79.40%, Valid: 71.49% Test: 69.21%\n",
      "Run: 01, Epoch: 446, Loss: 0.7103, Train: 79.17%, Valid: 72.01% Test: 70.00%\n",
      "Run: 01, Epoch: 447, Loss: 0.7112, Train: 79.53%, Valid: 72.37% Test: 70.35%\n",
      "Run: 01, Epoch: 448, Loss: 0.7076, Train: 79.06%, Valid: 71.29% Test: 68.81%\n",
      "Run: 01, Epoch: 449, Loss: 0.7126, Train: 79.22%, Valid: 72.10% Test: 69.56%\n",
      "Run: 01, Epoch: 450, Loss: 0.7095, Train: 79.39%, Valid: 72.55% Test: 70.82%\n",
      "Run: 01, Epoch: 451, Loss: 0.7123, Train: 79.11%, Valid: 71.77% Test: 70.05%\n",
      "Run: 01, Epoch: 452, Loss: 0.7128, Train: 79.04%, Valid: 72.28% Test: 71.72%\n",
      "Run: 01, Epoch: 453, Loss: 0.7114, Train: 78.87%, Valid: 71.62% Test: 69.71%\n",
      "Run: 01, Epoch: 454, Loss: 0.7106, Train: 79.08%, Valid: 72.40% Test: 70.53%\n",
      "Run: 01, Epoch: 455, Loss: 0.7139, Train: 78.84%, Valid: 71.68% Test: 70.16%\n",
      "Run: 01, Epoch: 456, Loss: 0.7164, Train: 79.28%, Valid: 72.55% Test: 71.27%\n",
      "Run: 01, Epoch: 457, Loss: 0.7140, Train: 79.00%, Valid: 71.68% Test: 69.73%\n",
      "Run: 01, Epoch: 458, Loss: 0.7116, Train: 79.25%, Valid: 72.50% Test: 71.20%\n",
      "Run: 01, Epoch: 459, Loss: 0.7113, Train: 79.27%, Valid: 72.94% Test: 72.03%\n",
      "Run: 01, Epoch: 460, Loss: 0.7108, Train: 79.36%, Valid: 72.14% Test: 70.24%\n",
      "Run: 01, Epoch: 461, Loss: 0.7068, Train: 79.53%, Valid: 71.96% Test: 69.76%\n",
      "Run: 01, Epoch: 462, Loss: 0.7087, Train: 79.66%, Valid: 72.77% Test: 71.43%\n",
      "Run: 01, Epoch: 463, Loss: 0.7059, Train: 79.31%, Valid: 72.18% Test: 70.73%\n",
      "Run: 01, Epoch: 464, Loss: 0.7094, Train: 79.09%, Valid: 72.10% Test: 70.58%\n",
      "Run: 01, Epoch: 465, Loss: 0.7092, Train: 79.41%, Valid: 72.95% Test: 71.52%\n",
      "Run: 01, Epoch: 466, Loss: 0.7067, Train: 79.42%, Valid: 72.50% Test: 70.86%\n",
      "Run: 01, Epoch: 467, Loss: 0.7056, Train: 79.38%, Valid: 72.44% Test: 70.65%\n",
      "Run: 01, Epoch: 468, Loss: 0.7070, Train: 79.58%, Valid: 72.36% Test: 70.22%\n",
      "Run: 01, Epoch: 469, Loss: 0.7050, Train: 79.67%, Valid: 72.55% Test: 70.67%\n",
      "Run: 01, Epoch: 470, Loss: 0.7041, Train: 79.76%, Valid: 71.95% Test: 69.58%\n",
      "Run: 01, Epoch: 471, Loss: 0.7038, Train: 79.68%, Valid: 72.37% Test: 70.52%\n",
      "Run: 01, Epoch: 472, Loss: 0.7057, Train: 79.78%, Valid: 72.74% Test: 71.43%\n",
      "Run: 01, Epoch: 473, Loss: 0.7044, Train: 79.82%, Valid: 72.41% Test: 70.87%\n",
      "Run: 01, Epoch: 474, Loss: 0.7016, Train: 79.60%, Valid: 72.49% Test: 71.10%\n",
      "Run: 01, Epoch: 475, Loss: 0.7061, Train: 79.37%, Valid: 71.46% Test: 69.34%\n",
      "Run: 01, Epoch: 476, Loss: 0.7137, Train: 79.40%, Valid: 72.70% Test: 71.52%\n",
      "Run: 01, Epoch: 477, Loss: 0.7109, Train: 78.50%, Valid: 69.89% Test: 66.67%\n",
      "Run: 01, Epoch: 478, Loss: 0.7089, Train: 79.51%, Valid: 71.84% Test: 69.64%\n",
      "Run: 01, Epoch: 479, Loss: 0.7074, Train: 79.58%, Valid: 72.48% Test: 70.96%\n",
      "Run: 01, Epoch: 480, Loss: 0.7081, Train: 79.49%, Valid: 71.55% Test: 69.46%\n",
      "Run: 01, Epoch: 481, Loss: 0.7110, Train: 79.56%, Valid: 72.38% Test: 71.24%\n",
      "Run: 01, Epoch: 482, Loss: 0.7037, Train: 79.66%, Valid: 72.15% Test: 70.34%\n",
      "Run: 01, Epoch: 483, Loss: 0.7040, Train: 79.57%, Valid: 71.92% Test: 69.97%\n",
      "Run: 01, Epoch: 484, Loss: 0.7040, Train: 79.43%, Valid: 72.74% Test: 71.92%\n",
      "Run: 01, Epoch: 485, Loss: 0.7023, Train: 79.37%, Valid: 72.73% Test: 71.33%\n",
      "Run: 01, Epoch: 486, Loss: 0.7018, Train: 79.40%, Valid: 72.10% Test: 69.99%\n",
      "Run: 01, Epoch: 487, Loss: 0.7100, Train: 79.56%, Valid: 72.85% Test: 71.75%\n",
      "Run: 01, Epoch: 488, Loss: 0.7001, Train: 79.44%, Valid: 72.07% Test: 70.01%\n",
      "Run: 01, Epoch: 489, Loss: 0.7037, Train: 79.07%, Valid: 70.38% Test: 67.11%\n",
      "Run: 01, Epoch: 490, Loss: 0.7041, Train: 79.54%, Valid: 72.21% Test: 70.31%\n",
      "Run: 01, Epoch: 491, Loss: 0.7039, Train: 79.84%, Valid: 72.13% Test: 69.96%\n",
      "Run: 01, Epoch: 492, Loss: 0.7017, Train: 79.46%, Valid: 71.63% Test: 69.76%\n",
      "Run: 01, Epoch: 493, Loss: 0.7033, Train: 79.48%, Valid: 71.85% Test: 69.93%\n",
      "Run: 01, Epoch: 494, Loss: 0.7019, Train: 79.47%, Valid: 71.92% Test: 69.41%\n",
      "Run: 01, Epoch: 495, Loss: 0.6992, Train: 79.45%, Valid: 71.99% Test: 70.00%\n",
      "Run: 01, Epoch: 496, Loss: 0.6971, Train: 78.98%, Valid: 71.34% Test: 69.08%\n",
      "Run: 01, Epoch: 497, Loss: 0.7008, Train: 79.72%, Valid: 72.04% Test: 70.06%\n",
      "Run: 01, Epoch: 498, Loss: 0.7015, Train: 79.70%, Valid: 72.32% Test: 70.35%\n",
      "Run: 01, Epoch: 499, Loss: 0.7051, Train: 79.50%, Valid: 72.69% Test: 71.44%\n",
      "Run: 01, Epoch: 500, Loss: 0.7022, Train: 79.40%, Valid: 72.35% Test: 70.99%\n",
      "Best test accuracy: 72.47%\n"
     ]
    }
   ],
   "source": [
    "data.adj_t = torch_sparse.fill_diag(data.adj_t, 1)\n",
    "deg = torch_sparse.sum(data.adj_t, 0).pow_(-0.5)\n",
    "data.adj_t = torch_sparse.mul(data.adj_t, deg.view(-1, 1))\n",
    "data.adj_t = torch_sparse.mul(data.adj_t, deg.view(1, -1))\n",
    "\n",
    "test_scores = []\n",
    "for epoch in range(1, 1 + epochs):\n",
    "    loss = train(model, data, train_idx, optimizer, criterion)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "\n",
    "    if epoch % log_steps == 0:\n",
    "        train_acc, valid_acc, test_acc = result\n",
    "        test_scores.append(test_acc)\n",
    "        print(f'Run: {1:02d}, '\n",
    "              f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_acc:.2f}%, '\n",
    "              f'Valid: {100 * valid_acc:.2f}% '\n",
    "              f'Test: {100 * test_acc:.2f}%')\n",
    "print(f\"Best test accuracy: {max(test_scores) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
