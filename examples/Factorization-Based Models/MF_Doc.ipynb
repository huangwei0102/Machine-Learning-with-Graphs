{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 基于矩阵分解的图机器学习模型\n",
    "\n",
    "## 1. Introduction\n",
    "极大的受到Dimensionality Reduction思想的影响，在图机器学习最早期的研究中涌现了一批基于Matrix Factorization的模型。这类模型往往以重建图的邻接矩阵为目标，学习各个节点的表示。在这篇文章中，我们将介绍其中三篇比较有代表性的工作，包括Graph Factorization<sup>[1]</sup>，GraRep<sup>[2]</sup>以及HOPE<sup>[3]</sup>。同时，在文章最后我们也提供了这三个模型的Pytorch Demo。因笔者能力有限，若有谬误，请不吝指正！\n",
    "\n",
    "## 2. Graph Factorization\n",
    "GF<sup>[1]</sup>是Google在13年提出的一篇文章，可以说是最早的图机器学习模型之一。它的思想在今天看来十分简单粗暴。\n",
    "\n",
    "### 2.1 Objective Function\n",
    "\n",
    "\n",
    "我们直接上目标函数：\n",
    "\n",
    "$$\\mathcal{L}=\\frac{1}{2} \\sum_{(i, j) \\in E}\\left(y_{i j}-\\left\\langle h_{i}, h_{j}\\right\\rangle\\right)^{2}+\\frac{\\lambda}{2} \\sum_{i}\\left\\|h_{i}\\right\\|^{2},$$\n",
    "\n",
    "其中，$y_{ij}$为节点$(i,j)$之间的边权重，$h_i$为节点$i$的表示，$h_j$为节点$j$的表示，$\\lambda$为正则系数。在整篇专栏中，我们将尽可能统一各符号的含义，因此公示符号会和原论文中的略有不同。\n",
    "\n",
    "显然，这是一个简单的$MSE$目标函数加上一个$L_2$正则项。该目标函数希望节点对的表示的内积可以重建$y_{ij}$。当$y_{ij}$为边权重时，该目标等同重建图的邻接矩阵。换句话说，该目标可以看作是一个关于$y_{ij}$的回归模型，因此这也往往要求$y_{ij}$是连续的，否则模型效果可能会有极大的损失。值得一提的是，尽管原论文中没有提到，但这里的$y_{ij}$也可以为任意的一维（连续）edge feature。\n",
    "\n",
    "### 2.2 Graph Partitioning\n",
    "这个损失函数的设计思路是显而易见的，但该模型存在一个显著的问题。即，当图中节点数量较大，并且嵌入的维度不小时，我们可能很难将整张图存在单个机器的内存中。\n",
    "\n",
    "为了解决这一问题，一个直观的思路就是将图数据分布式的存储在集群中，后进行分布式的训练。基于这一思路，该文章提出了一个Graph Partitioning算法，使得该分解过程scalable，而这个算法事实上才是这篇文章的主要贡献。\n",
    "\n",
    "<img src=\"img/GraphPartitioning.jpg\"  width=\"300\">\n",
    "\n",
    "### 2.3 Pros & Cons\n",
    "从今天的眼光来看，这个模型有较大的局限性：\n",
    "\n",
    "- 往往仅适用于连续的$y_{ij}$，且仅能捕捉节点间的一阶关系。\n",
    "- 模型仅输入$(i,j) \\in E$，故而缺少“负”样本，可能出现较多的False Positives。\n",
    "- Embedding lookup矩阵后直接跟损失函数，模型表达能力有限、节点间无参数共享。\n",
    "- 无法利用节点的特征。\n",
    "\n",
    "### 2.4 Summarization\n",
    "\n",
    "## 3. GraRep\n",
    "\n",
    "## 4. HOPE\n",
    "\n",
    "## 5. References\n",
    "[1] Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy,\n",
    "Vanja Josifovski, and Alexander J Smola. Distributed\n",
    "large-scale natural graph factorization. In\n",
    "Proceedings of the 22nd international conference on\n",
    "World Wide Web, pages 37–48, 2013.\n",
    "\n",
    "[2] Shaosheng Cao, Wei Lu, and Qiongkai Xu. Grarep:\n",
    "Learning graph representations with global structural\n",
    "information. In Proceedings of the 24th ACM international\n",
    "on conference on information and knowledge\n",
    "management, pages 891–900, 2015.\n",
    "\n",
    "[3] Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang,\n",
    "and Wenwu Zhu. Asymmetric transitivity preserving\n",
    "graph embedding. In Proceedings of the 22nd ACM\n",
    "SIGKDD international conference on Knowledge discovery\n",
    "and data mining, pages 1105–1114, 2016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}